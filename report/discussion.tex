% Evaluation criterion:
%- Language and use of figures
%- Clarity of the problem statement
%- Overall document structure
%- Depth of understanding for the Ô¨Åeld of computer architecture
%- Depth of understanding of the investigated problem

\section{Discussion} % (fold)
\label{sec:discussion}

Can only be written when results are present.
Things to consider:

\paragraph{Variability of Prefetcher Performance}
\label{par:varprefperf}

The more complex prefetchers perform better on average. Specifically, the GHB
prefetcher has the highest performance. However, the difference is not
very large except for a few benchmarks. These exceptions are most
likely occuring because the benchmark programs have a memory access pattern
which corresponds well with the prefetcher which excells.

%For instance, on the benchmark ammp the GHB prefetcher is able to
%achieve many times the speedup of the other prefetchers. This program
%operates on the 

One benchmark on which the GHB prefetcher was outperformed was the
galgel benchmark, on which the stride prefetcher got an average
speedup almost five times as high. 


%  - Are there any variance as to which programs they yield good speedup
%  on?  

%  According to the results in \autoref{fig:initResults}.  The more
%  complex ones are usually better overall, however there are some
%  programs which 

% - How would combining them work?

\paragraph{Combining Prefetchers}
\label{par:prefcombo}
Since the prefetchers have somewhat varying performance on the
different programs, it might be a good idea to attempt to combine
them. This could be done in two ways. One way would be to try and
merge the two algorithms into a single prefetching algorithm. Another
way would be to create a controlling unit utilizing heuristics to
choose which of the two prefetchers should be used at a given time.

The first such strategy is especially applicable to the stride and GHB
prefetchers. The GHB is in essence almost a stride prefetcher, since a
constant delta stride will also be recognized. However, as there would
only be two more items left in the delta table after the point of
matching, only two addresses will be prefetched. According to
\autoref{tab:stridesettings}, this is most likely fewer addresses than
would be optimal. Therefore, one could try to recognize this special
case by checking when the final four elements of the delta table are
identical, and prefetch a larger set of blocks the constant stride
apart. The results from running the GHB prefetcher with this change
included is shown in \autoref{tab:ghbstridetab}.

\paragraph{Uncertainties}
\label{"waiting for reftex-label call..."}
The four prefetchers discussed in this report varies widely in complexity. One factor that is not considered when using the simulation environment is the time required by the prefetchers to perform its calculations. 

Another factor that is not taken into consideration is that the two address based prefetchers (stride and markov) would occupy less critical CPU surface, as it would not require having access to the program counter. The program counter based prefetchers would need to be implemented close enough to the CPU to have access to the program counter, or would need to have the program counter passed on to them. Both of theses solutions would affect the overall performance enhancement of the prefetchers. 
- Considering how the time spent by our prefetching algorithms is not
taken into account, are our results at all accurate and usable?

- Are our implementations perhaps not correct?
- Simulation environment misunderstandings?

- Anything else?

{\bf (references, citations)}
